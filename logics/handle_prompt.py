from helper_functions import llm


def rephrase_user_input_into_promp(context):
    prompt = f"""
    You are an scientist with a huge wealth of scientific knowlegde, well versed in all fields and disciplines. 
    Below is some context, a proposal title or a summary of a proposal.
    provide a summary in less than 100 words what the proposal using simple language in 1 paragraph. Next list down all the disciplines or subfields you think the proposal falls under, be as detailed as possible 

    Context:
    {context}
    """
    return prompt

#example 1 generated by chatgpt on Additive manufacturing
'''
"Optimization of Material Properties in 3D Printed Structures for Enhanced Performance in Aerospace Applications"

This research aims to explore the optimization of material properties in additive manufacturing (AM) for aerospace applications. By investigating novel composite materials and adjusting printing parameters, we aim to improve the mechanical strength, durability, and thermal resistance of 3D printed parts. The study will utilize advanced simulation techniques and experimental validation to develop a set of guidelines for producing high-performance AM components, addressing critical needs in the aerospace industry such as weight reduction, efficiency, and reliability.
'''

#example 2 generated by chatgpt on  microbiology and radiation

'''
"Impact of Low-Dose Radiation on Microbial Resistance and Evolution"

This research aims to investigate the effects of low-dose radiation on microbial resistance and evolutionary adaptations. By exposing various bacterial strains to controlled radiation levels, the study will explore how radiation influences genetic mutations, resistance mechanisms, and microbial community dynamics. The findings could provide insights into microbial survival strategies in environments with elevated radiation, such as space, nuclear sites, and medical settings, with potential implications for public health, environmental safety, and understanding radiation-induced evolutionary processes.
'''

def process_user_message(user_input):
    #delimiter = "```"

    # Process 1: If Courses are found, look them up
    #category_n_course_name = identify_category_and_courses(user_input)
    #print("category_n_course_name : ", category_n_course_name)

    # Process 2: Get the Course Details
    #course_details = get_course_details(category_n_course_name)

    # Process 3: Generate Response based on Course Details
    #reply = generate_response_based_on_course_details(user_input, course_details)
    prompt=rephrase_user_input_into_promp(user_input)
    initial_summary=llm.get_completion(prompt)
    
    return initial_summary


def conver_to_markdown(list_of_docs):
    # Create the markdown table header
    markdown = "| name | h-index |  gender | Content | \n"
    markdown += "|----------|-------|---------|---------|\n"
    
    # Iterate through each retriever result and create a table row
    for result in list_of_docs:
        name = result.metadata.get("Name", "N/A")
        score = result.metadata.get("H-Index", "N/A")
        gender = result.metadata.get("Gender", "N/A")
        out_text=result.page_content
        content = out_text.replace("\t", " ").replace("\n", " ")
         

        
        # Format the row and add it to the markdown string
        markdown += f"| {name} | {score} | {gender} |{content} |\n"
    
    return markdown
    
def create_prompt_with_table(context, query, markdown_table):

    prompt = f"""
    You are an scientist with a huge wealth of knowlegde. 
    Below is some context, a markdown table, and a query. identify 3 suitable reviewers, rate their suitability to review a proposal based on the query on a scale of 1 to 100
    Present your answer in a markdown table with no extra text or formatting or preamble with the following columns, name of reviewer, rating, list of expertise, reason why this reviewer may be a good fit

    Context:
    {context}

    Table:
    {markdown_table}

    Query:
    {query}

    Answer:
    """
    return prompt
    
def return_final_choices(context, query, markdown_table):
    new_prompt=create_prompt_with_table(context, query, markdown_table)
    final_markdown_table=llm.get_completion(new_prompt)
    return final_markdown_table
